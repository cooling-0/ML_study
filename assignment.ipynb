{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM6iiCJuzlHmSkew2kBHf1X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"90a33c5132d945c58e4877de83968910":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_49ccf689eff84e92b9b7b58d75cdfa6d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_17b5bdce513b42048ac8179536f350c4","IPY_MODEL_1d3d644c3d9d404c9cd8775f60f480ef"]}},"49ccf689eff84e92b9b7b58d75cdfa6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17b5bdce513b42048ac8179536f350c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe6bd9d6a36a4fff92e9a94cd67090dc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da6825bd968e4b7f88768d2d879db13c"}},"1d3d644c3d9d404c9cd8775f60f480ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f09b81bb6cb641e0b2ce72648010cc61","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:57&lt;00:00, 2957047.75it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe8e719576d247dcade6f5f1c2ee53c5"}},"fe6bd9d6a36a4fff92e9a94cd67090dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da6825bd968e4b7f88768d2d879db13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f09b81bb6cb641e0b2ce72648010cc61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe8e719576d247dcade6f5f1c2ee53c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"byBt59LVjzfv"},"source":["!pip install -q torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHdRyx3SmZ21"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import argparse\n","import numpy as np\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJyckLqah2n4","colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["90a33c5132d945c58e4877de83968910","49ccf689eff84e92b9b7b58d75cdfa6d","17b5bdce513b42048ac8179536f350c4","1d3d644c3d9d404c9cd8775f60f480ef","fe6bd9d6a36a4fff92e9a94cd67090dc","da6825bd968e4b7f88768d2d879db13c","f09b81bb6cb641e0b2ce72648010cc61","fe8e719576d247dcade6f5f1c2ee53c5"]},"executionInfo":{"status":"ok","timestamp":1618053678934,"user_tz":-540,"elapsed":7041,"user":{"displayName":"Chan Young Jung","photoUrl":"","userId":"10251187377679903800"}},"outputId":"ea2e2ce4-c8a8-491c-c55a-4fccf666b103"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","partition = {'train': trainset, 'val':valset, 'test':testset}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90a33c5132d945c58e4877de83968910","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"45IQFOcOi4Ts"},"source":["class MLP(nn.Module):\n","  def __init__(self, in_dim, out_dim, hid_dim, n_layer, act, dropout):\n","    super(MLP, self).__init__()\n","    self.in_dim = in_dim    #int\n","    self.out_dim = out_dim  #int\n","    self.hid_dim = hid_dim  #int\n","    self.n_layer = n_layer  #int\n","    self.act = act          #sigmoid or relu default = relu\n","    self.dropout = dropout  #floor\n","\n","    self.fc1 = nn.Linear(self.in_dim, self.hid_dim)  # input layer\n","    self.linears = nn.ModuleList()\n","\n","\n","    # output layer를 제외하고 hiddien layer 만들기\n","    for i in range(self.n_layer - 1):\n","      self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n","    \n","    self.fc2 = nn.Linear(self.hid_dim, self.out_dim) # output layer\n","\n","    # Activation func\n","    if self.act == 'sigmoid':\n","      self.act = nn.Sigmoid()\n","    else:\n","      self.act = nn.ReLU()\n","\n","    # dropout\n","    self.dropout = nn.Dropout(self.dropout)\n","\n","  def forward(self, x):\n","    x = self.fc1(x)\n","    for i in range(len(self.linears)):\n","      x = self.act(self.linears[i](x))\n","      x = self.dropout(x)\n","    x = self.fc2(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_WNIWFli-F7"},"source":["def train(model, partition, optimizer, criterion, args):\n","  #train_data\n","  trainloader = torch.utils.data.DataLoader(partition['train'],\n","                                            batch_size = args.train_batch_size,\n","                                            shuffle = True,\n","                                            num_workers = 2)\n","  \n","  # model이 학습할수 있게 만들기\n","  model.train()\n","  correct = 0\n","  total = 0\n","  train_loss = 0\n","  for i, data in enumerate(trainloader, 0):\n","    optimizer.zero_grad()\n","\n","    # 데이터를 GPU에 돌리기위해 변형 후 output값 출력 \n","    inputs, labels = data\n","    inputs = inputs.view(-1, 3072) # flatten개념인거 같음\n","    inputs = inputs.cuda()\n","    labels = labels.cuda()\n","    outputs = model(inputs) \n","\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    train_loss = loss.item()\n","    _, predicted = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","\n","  train_loss = train_loss / len(trainloader)\n","  train_acc = 100 * correct / total\n","\n","  return model, train_loss, train_acc\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gqW-r8-8kD34"},"source":["def validate(model, partition, criterion, args):\n","    valloader = torch.utils.data.DataLoader(partition['val'], \n","                                            batch_size=args.test_batch_size, \n","                                            shuffle=False,\n","                                            num_workers=2)\n","    model.eval()\n","\n","    correct = 0\n","    total = 0\n","    val_loss = 0 \n","    with torch.no_grad():\n","        for data in valloader:\n","            images, labels = data\n","            images = images.view(-1, 3072)\n","            images = images.cuda()\n","            labels = labels.cuda()\n","            outputs = model(images)\n","\n","            loss = criterion(outputs, labels)\n","            \n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        val_loss = val_loss / len(valloader)\n","        val_acc = 100 * correct / total\n","    return val_loss, val_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"83LpDTcwomLY"},"source":["def test(model, partition, args):\n","    testloader = torch.utils.data.DataLoader(partition['test'], \n","                                             batch_size=args.test_batch_size, \n","                                             shuffle=False,\n","                                             num_workers=2)\n","    model.eval()\n","    \n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images = images.view(-1, 3072)\n","            images = images.cuda()\n","            labels = labels.cuda()\n","\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","        test_acc = 100 * correct / total\n","    return test_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vejZ4Gai6ISh"},"source":["def experiment(partition, args):\n","  \n","    model = MLP(args.in_dim, args.out_dim, args.hid_dim, args.n_layer, args.act, args.dropout)\n","    model.cuda()\n","\n","    criterion = nn.CrossEntropyLoss()\n","    if args.optim == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'RMSprop':\n","        optimizer = optim.RMSprop(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    elif args.optim == 'Adam':\n","        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2)\n","    else:\n","        raise ValueError('In-valid optimizer choice')\n","    \n","    for epoch in range(args.epoch):  # loop over the dataset multiple times\n","        ts = time.time()\n","        model, train_loss, train_acc = train(model, partition, optimizer, criterion, args)\n","        val_loss, val_acc = validate(model, partition, criterion, args)\n","        te = time.time()\n","        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n","        \n","    test_acc = test(model, partition, args)    \n","    return train_loss, val_loss, train_acc, val_acc, test_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSTvrydFp-e_"},"source":["import argparse\n","\n","seed = 123\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","parser = argparse.ArgumentParser()\n","args = parser.parse_args(\"\")\n","\n","args.n_layer = 5\n","args.in_dim = 3072\n","args.out_dim = 10\n","args.hid_dim = 100\n","args.act = 'relu'\n","\n","args.lr = 0.001\n","args.dropout = 0.2\n","args.l2 = 0.00001\n","\n","args.epoch = 5\n","args.optim = 'Adam'\n","\n","args.train_batch_size = 256\n","args.test_batch_size = 1024"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMhXY_ynq9km","executionInfo":{"status":"ok","timestamp":1618063519423,"user_tz":-540,"elapsed":430439,"user":{"displayName":"Chan Young Jung","photoUrl":"","userId":"10251187377679903800"}},"outputId":"af6251f5-6ab1-42ab-9ff7-6d463aae25b9"},"source":["hid_dim_num = []\n","layer_num = []\n","results ={'train_loss': [],\n","          'val_loss' : [],\n","          'train_acc' : [],\n","          'val_acc' : [],\n","          'test_acc' : []}\n","\n","\n","for i in range(10):\n","  var1 = np.random.randint(3,10)\n","  var2 = 2 ** np.random.randint(5,12)\n","  args.n_layer = var1\n","  args.hid_dim = var2\n","  result = experiment(partition, args)\n","  hid_dim_num.append(args.hid_dim)\n","  layer_num.append(args.n_layer)\n","  results['train_loss'].append(result[0])\n","  results['val_loss'].append(result[1])\n","  results['train_acc'].append(result[2])\n","  results['val_acc'].append(result[3])\n","  results['test_acc'].append(result[4])\n","  print('======================================')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0, Acc(train/val): 17.17/19.30, Loss(train/val) 0.01/2.00. Took 8.50 sec\n","Epoch 1, Acc(train/val): 24.49/29.52, Loss(train/val) 0.01/1.84. Took 8.45 sec\n","Epoch 2, Acc(train/val): 31.35/33.31, Loss(train/val) 0.01/1.79. Took 8.46 sec\n","Epoch 3, Acc(train/val): 35.51/37.26, Loss(train/val) 0.01/1.70. Took 8.57 sec\n","Epoch 4, Acc(train/val): 38.06/40.70, Loss(train/val) 0.01/1.67. Took 8.55 sec\n","======================================\n","Epoch 0, Acc(train/val): 16.88/19.00, Loss(train/val) 0.01/1.99. Took 8.34 sec\n","Epoch 1, Acc(train/val): 24.25/28.41, Loss(train/val) 0.01/1.85. Took 8.38 sec\n","Epoch 2, Acc(train/val): 29.86/33.06, Loss(train/val) 0.01/1.77. Took 8.25 sec\n","Epoch 3, Acc(train/val): 33.47/36.61, Loss(train/val) 0.01/1.71. Took 8.34 sec\n","Epoch 4, Acc(train/val): 36.52/37.74, Loss(train/val) 0.01/1.69. Took 8.23 sec\n","======================================\n","Epoch 0, Acc(train/val): 23.40/31.45, Loss(train/val) 0.01/1.82. Took 8.09 sec\n","Epoch 1, Acc(train/val): 33.06/36.79, Loss(train/val) 0.01/1.73. Took 8.09 sec\n","Epoch 2, Acc(train/val): 38.12/40.46, Loss(train/val) 0.01/1.66. Took 7.94 sec\n","Epoch 3, Acc(train/val): 40.83/43.18, Loss(train/val) 0.01/1.59. Took 7.98 sec\n","Epoch 4, Acc(train/val): 42.70/44.09, Loss(train/val) 0.01/1.55. Took 7.99 sec\n","======================================\n","Epoch 0, Acc(train/val): 16.32/17.35, Loss(train/val) 0.01/2.02. Took 8.12 sec\n","Epoch 1, Acc(train/val): 19.80/24.95, Loss(train/val) 0.01/1.92. Took 8.17 sec\n","Epoch 2, Acc(train/val): 24.84/27.88, Loss(train/val) 0.01/1.86. Took 8.22 sec\n","Epoch 3, Acc(train/val): 27.54/29.55, Loss(train/val) 0.01/1.80. Took 8.18 sec\n","Epoch 4, Acc(train/val): 29.59/30.66, Loss(train/val) 0.01/1.78. Took 8.19 sec\n","======================================\n","Epoch 0, Acc(train/val): 27.97/37.12, Loss(train/val) 0.01/1.75. Took 8.04 sec\n","Epoch 1, Acc(train/val): 37.83/41.06, Loss(train/val) 0.01/1.64. Took 7.95 sec\n","Epoch 2, Acc(train/val): 41.61/43.04, Loss(train/val) 0.01/1.58. Took 7.92 sec\n","Epoch 3, Acc(train/val): 43.37/45.10, Loss(train/val) 0.01/1.54. Took 7.94 sec\n","Epoch 4, Acc(train/val): 44.75/46.58, Loss(train/val) 0.01/1.52. Took 8.04 sec\n","======================================\n","Epoch 0, Acc(train/val): 23.66/32.14, Loss(train/val) 0.01/1.84. Took 7.97 sec\n","Epoch 1, Acc(train/val): 32.19/36.60, Loss(train/val) 0.01/1.74. Took 8.15 sec\n","Epoch 2, Acc(train/val): 36.70/40.38, Loss(train/val) 0.01/1.66. Took 8.13 sec\n","Epoch 3, Acc(train/val): 39.07/42.07, Loss(train/val) 0.01/1.62. Took 8.27 sec\n","Epoch 4, Acc(train/val): 40.74/43.18, Loss(train/val) 0.01/1.59. Took 8.12 sec\n","======================================\n","Epoch 0, Acc(train/val): 16.43/19.44, Loss(train/val) 0.01/2.03. Took 8.26 sec\n","Epoch 1, Acc(train/val): 19.96/25.09, Loss(train/val) 0.01/1.92. Took 8.29 sec\n","Epoch 2, Acc(train/val): 26.14/29.35, Loss(train/val) 0.01/1.84. Took 8.37 sec\n","Epoch 3, Acc(train/val): 28.55/30.71, Loss(train/val) 0.01/1.82. Took 8.22 sec\n","Epoch 4, Acc(train/val): 30.51/32.55, Loss(train/val) 0.01/1.78. Took 8.39 sec\n","======================================\n","Epoch 0, Acc(train/val): 32.15/40.35, Loss(train/val) 0.01/1.70. Took 8.11 sec\n","Epoch 1, Acc(train/val): 39.54/42.61, Loss(train/val) 0.01/1.62. Took 8.09 sec\n","Epoch 2, Acc(train/val): 42.04/44.09, Loss(train/val) 0.01/1.57. Took 8.07 sec\n","Epoch 3, Acc(train/val): 43.41/45.16, Loss(train/val) 0.01/1.54. Took 8.04 sec\n","Epoch 4, Acc(train/val): 44.67/46.25, Loss(train/val) 0.01/1.51. Took 8.16 sec\n","======================================\n","Epoch 0, Acc(train/val): 18.18/25.86, Loss(train/val) 0.01/1.95. Took 8.53 sec\n","Epoch 1, Acc(train/val): 24.10/26.79, Loss(train/val) 0.01/1.89. Took 8.61 sec\n","Epoch 2, Acc(train/val): 27.20/30.25, Loss(train/val) 0.01/1.82. Took 8.73 sec\n","Epoch 3, Acc(train/val): 29.81/32.94, Loss(train/val) 0.01/1.78. Took 8.56 sec\n","Epoch 4, Acc(train/val): 32.08/33.87, Loss(train/val) 0.01/1.74. Took 8.38 sec\n","======================================\n","Epoch 0, Acc(train/val): 37.23/42.87, Loss(train/val) 0.01/1.64. Took 8.52 sec\n","Epoch 1, Acc(train/val): 43.55/43.28, Loss(train/val) 0.01/1.61. Took 8.44 sec\n","Epoch 2, Acc(train/val): 45.66/45.74, Loss(train/val) 0.01/1.56. Took 8.49 sec\n","Epoch 3, Acc(train/val): 47.27/46.78, Loss(train/val) 0.01/1.51. Took 8.37 sec\n","Epoch 4, Acc(train/val): 49.15/46.51, Loss(train/val) 0.01/1.54. Took 8.50 sec\n","======================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nN1B7PRMAwdo","executionInfo":{"status":"ok","timestamp":1618063554032,"user_tz":-540,"elapsed":845,"user":{"displayName":"Chan Young Jung","photoUrl":"","userId":"10251187377679903800"}},"outputId":"cd718483-f1d6-4688-8055-820340ffb26f"},"source":["results"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'test_acc': [41.4,\n","  38.93,\n","  45.62,\n","  31.96,\n","  46.8,\n","  44.95,\n","  32.68,\n","  46.62,\n","  35.09,\n","  46.93],\n"," 'train_acc': [38.065,\n","  36.5225,\n","  42.705,\n","  29.5875,\n","  44.7475,\n","  40.74,\n","  30.5125,\n","  44.675,\n","  32.08,\n","  49.1475],\n"," 'train_loss': [0.011238088273698358,\n","  0.012147927739817625,\n","  0.012042118485566158,\n","  0.011706244414019736,\n","  0.00999213859533808,\n","  0.010595375565206929,\n","  0.012377125442407693,\n","  0.009947414610795914,\n","  0.011670624374584028,\n","  0.007521863196306168],\n"," 'val_acc': [40.7,\n","  37.74,\n","  44.09,\n","  30.66,\n","  46.58,\n","  43.18,\n","  32.55,\n","  46.25,\n","  33.87,\n","  46.51],\n"," 'val_loss': [1.6668489933013917,\n","  1.685024619102478,\n","  1.5544967532157898,\n","  1.7814177036285401,\n","  1.5183439373970031,\n","  1.5940255045890808,\n","  1.7820457220077515,\n","  1.5123131155967713,\n","  1.7436251282691955,\n","  1.5350501656532287]}"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAMbZlfGAxMT","executionInfo":{"status":"ok","timestamp":1618063559957,"user_tz":-540,"elapsed":1383,"user":{"displayName":"Chan Young Jung","photoUrl":"","userId":"10251187377679903800"}},"outputId":"316ed40c-600a-4605-f4f7-700174a9b55f"},"source":["layer_num"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[9, 9, 7, 9, 6, 6, 9, 3, 9, 3]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIG2FntmDTDz","executionInfo":{"status":"ok","timestamp":1618063573905,"user_tz":-540,"elapsed":1009,"user":{"displayName":"Chan Young Jung","photoUrl":"","userId":"10251187377679903800"}},"outputId":"65be6ad3-0ab0-42e6-d6a8-51b569938c76"},"source":["hid_dim_num"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1024, 128, 128, 64, 128, 64, 64, 64, 64, 2048]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"9wWHN-YAGr9p"},"source":["# layer가 작고 hidden node의 수가 많을때 좋은 결과가 있는거 같다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UocYD1WPHCFW"},"source":[""],"execution_count":null,"outputs":[]}]}